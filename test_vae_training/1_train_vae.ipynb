{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d904319",
   "metadata": {},
   "source": [
    "# Train VAE model\n",
    "\n",
    "This notebook will first try to train the current VAE model before modifying the loss function to work with count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b819c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/ponyo/helper_vae.py:21: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from ponyo import utils, train_vae_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14176d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/ponyo/train_vae_modules.py:56: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seeds to get reproducible VAE trained models\n",
    "train_vae_modules.set_all_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f225d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "# Read in config variables\n",
    "config_filename = os.path.abspath(\n",
    "    os.path.join(base_dir, \"test_vae_training\", \"config_current_vae.tsv\")\n",
    ")\n",
    "\n",
    "params = utils.read_config(config_filename)\n",
    "\n",
    "dataset_name = params[\"dataset_name\"]\n",
    "\n",
    "normalized_compendium_filename = params[\"normalized_compendium_filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b77d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE directories if needed\n",
    "output_dirs = [\n",
    "    os.path.join(base_dir, dataset_name, \"models\"),\n",
    "    os.path.join(base_dir, dataset_name, \"logs\"),\n",
    "]\n",
    "\n",
    "NN_architecture = params[\"NN_architecture\"]\n",
    "\n",
    "# Check if NN architecture directory exist otherwise create\n",
    "for each_dir in output_dirs:\n",
    "    sub_dir = os.path.join(each_dir, NN_architecture)\n",
    "    os.makedirs(sub_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82898aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dataset contains 11857 samples and 1232 genes\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=float32> beta\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output custom_variational_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/microbe/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8893 samples, validate on 2964 samples\n",
      "Epoch 1/40\n",
      "8893/8893 [==============================] - 63s 7ms/step - loss: -2032937489.9980 - val_loss: -21558715781.8839\n",
      "Epoch 2/40\n",
      "8893/8893 [==============================] - 61s 7ms/step - loss: -26884823133.2401 - val_loss: -233159787756.8259\n",
      "Epoch 3/40\n",
      "8893/8893 [==============================] - 62s 7ms/step - loss: -99915669208.0729 - val_loss: -287163071262.0567\n",
      "Epoch 4/40\n",
      "8893/8893 [==============================] - 62s 7ms/step - loss: -231841317767.2111 - val_loss: -4158022170056.0327\n",
      "Epoch 5/40\n",
      "8893/8893 [==============================] - 62s 7ms/step - loss: -434632201390.9079 - val_loss: -1158254590670.5964\n",
      "Epoch 6/40\n",
      "8893/8893 [==============================] - 60s 7ms/step - loss: -704234125172.2119 - val_loss: -2658532588407.1904\n",
      "Epoch 7/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -1067440749388.9468 - val_loss: -1713740217450.4075\n",
      "Epoch 8/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -1515242244035.8936 - val_loss: -2500718020207.2441\n",
      "Epoch 9/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -2050017306815.3740 - val_loss: -3333570394136.8745\n",
      "Epoch 10/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -2713475899385.5518 - val_loss: -5234069139350.9746\n",
      "Epoch 11/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -3457970368702.2227 - val_loss: -11220504729248.9941\n",
      "Epoch 12/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -4352107607680.1006 - val_loss: -10037614467074.7637\n",
      "Epoch 13/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -5380936786952.6357 - val_loss: -79221437414782.7969\n",
      "Epoch 14/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -6504317924371.2295 - val_loss: -26678287666287.9336\n",
      "Epoch 15/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -7793796641982.5674 - val_loss: -14444570556982.5859\n",
      "Epoch 16/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -9196681346978.0391 - val_loss: -22396474709200.6680\n",
      "Epoch 17/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -10710235937113.6699 - val_loss: -15830283678077.4082\n",
      "Epoch 18/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -12510628720419.3789 - val_loss: -20456635491685.9180\n",
      "Epoch 19/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -14471684408558.0098 - val_loss: -35553095638299.2891\n",
      "Epoch 20/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -16447300899178.4824 - val_loss: -25306482252397.8633\n",
      "Epoch 21/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -18735786134650.6289 - val_loss: -27939012058417.4023\n",
      "Epoch 22/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -21155609137976.9102 - val_loss: -36400984020884.2109\n",
      "Epoch 23/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -23748468807460.9883 - val_loss: -54390133697857.9766\n",
      "Epoch 24/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -26684352403926.0273 - val_loss: -61279153789549.8516\n",
      "Epoch 25/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -29575172298227.1602 - val_loss: -89945914944126.4531\n",
      "Epoch 26/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -32814155807096.9922 - val_loss: -66089023301585.0234\n",
      "Epoch 27/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -36227619447035.4844 - val_loss: -91756113132020.2500\n",
      "Epoch 28/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -40290605039575.4688 - val_loss: -118420029768299.0781\n",
      "Epoch 29/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -43549408950956.6641 - val_loss: -70795506488152.7812\n",
      "Epoch 30/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -48170161336768.1484 - val_loss: -67663301515399.4297\n",
      "Epoch 31/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -52546162112785.8203 - val_loss: -118434837944123.7656\n",
      "Epoch 32/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -57150675213493.1250 - val_loss: -132455937447850.3281\n",
      "Epoch 33/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -62723886584070.9922 - val_loss: -160384745796053.8438\n",
      "Epoch 34/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -67683705041032.7891 - val_loss: -186888300123610.0000\n",
      "Epoch 35/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -73017910159925.3594 - val_loss: -101067803488062.5469\n",
      "Epoch 36/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -78470879323890.7969 - val_loss: -127097451598924.0000\n",
      "Epoch 37/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -85075647725516.4219 - val_loss: -120513035744254.6250\n",
      "Epoch 38/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -91233856345124.7344 - val_loss: -175563967501233.2188\n",
      "Epoch 39/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -98134671578944.6406 - val_loss: -562135990144996.3125\n",
      "Epoch 40/40\n",
      "8893/8893 [==============================] - 57s 6ms/step - loss: -104113814892601.5625 - val_loss: -163586672058379.0625\n"
     ]
    }
   ],
   "source": [
    "# Train VAE on new compendium data\n",
    "train_vae_modules.train_vae(config_filename, normalized_compendium_filename)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:microbe] *",
   "language": "python",
   "name": "conda-env-microbe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
